{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOopbeOLYDM92A5Sw1kDMeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubiraPokharel/TF-IDF-Implementation/blob/main/TF_IDF_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqvOFR7HvBLm"
      },
      "source": [
        "## 1. TF-IDF\n",
        "\n",
        "Implement TF-IDF using using Python, Numpy, Pandas and whatever text cleaning library required.\n",
        "\n",
        "The tfâ€“idf is the product of two statistics, term frequency and inverse document frequency. There are various ways for determining the exact values of both statistics, you can use the following formulas.\n",
        "\n",
        "### Term Frequency\n",
        "$$tf_{t,d} = \\log_{10}(count(t,d) +1)$$\n",
        "\n",
        "* $tf_{t,d}$ is the frequency of the word t in the\n",
        "document d\n",
        "\n",
        "### Inverse Document Frequency\n",
        "$$idf_t = \\log_{10}(\\frac{N}{df_t})$$\n",
        "\n",
        "* $N$ is the total number of documents\n",
        "* $df_t $ is the number of documents in which term t occurs\n",
        "\n",
        "### TF-IDF\n",
        "$$tf\\text{-}idf_{t,d} = tf_{t,d} \\times idf_t $$\n",
        "\n",
        "### What is expected?\n",
        "Your implementation should include the following two functions:\n",
        " * `compute_tfidf_weights(train_docs)`\n",
        " * `word_tfidf_vector(word, tf_df, idf_df)`\n",
        "\n",
        "To revise what TF-IDf is, you can revise the lecture notes and the further reading under Week 7.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS2YXV_ciVHJ",
        "outputId": "ee522b51-d2c4-4bc9-f27d-3e7cdb26d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF DataFrame:\n",
            "       this        is       the  first  document    second       and  \\\n",
            "0  0.200000  0.200000  0.200000    0.2  0.200000  0.000000  0.000000   \n",
            "1  0.166667  0.166667  0.166667    0.0  0.333333  0.166667  0.000000   \n",
            "2  0.166667  0.166667  0.166667    0.0  0.000000  0.000000  0.166667   \n",
            "3  0.200000  0.200000  0.200000    0.2  0.200000  0.000000  0.000000   \n",
            "\n",
            "      third       one  \n",
            "0  0.000000  0.000000  \n",
            "1  0.000000  0.000000  \n",
            "2  0.166667  0.166667  \n",
            "3  0.000000  0.000000  \n",
            "\n",
            "IDF DataFrame:\n",
            "               idf\n",
            "first     0.301030\n",
            "the       0.000000\n",
            "is        0.000000\n",
            "document  0.124939\n",
            "this      0.000000\n",
            "second    0.602060\n",
            "one       0.602060\n",
            "third     0.602060\n",
            "and       0.602060\n",
            "\n",
            "TF-IDF vector for 'document':\n",
            "[0.02498775 0.04164625 0.         0.02498775]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from math import log10\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean the input text by converting it to lowercase and removing special characters and numbers.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned text.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def compute_tf(train_docs):\n",
        "    \"\"\"\n",
        "    Compute the term frequency (TF) matrix for a list of documents.\n",
        "\n",
        "    Parameters:\n",
        "    train_docs (list of str): The list of documents for which TF is to be computed.\n",
        "\n",
        "    Returns:\n",
        "    list of dict: List of dictionaries where each dictionary contains the TF values for words in a document.\n",
        "    \"\"\"\n",
        "    tf_values = []\n",
        "    for doc in train_docs:\n",
        "        cleaned_doc = clean_text(doc)\n",
        "        word_count = Counter(cleaned_doc.split())\n",
        "        total_words = len(cleaned_doc.split())\n",
        "        tf_doc = {word: word_count[word] / total_words for word in word_count}\n",
        "        tf_values.append(tf_doc)\n",
        "    return tf_values\n",
        "\n",
        "def compute_idf(train_docs):\n",
        "    \"\"\"\n",
        "    Compute the inverse document frequency (IDF) matrix for a list of documents.\n",
        "\n",
        "    Parameters:\n",
        "    train_docs (list of str): The list of documents for which IDF is to be computed.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing IDF values for words in the document corpus.\n",
        "    \"\"\"\n",
        "    N = len(train_docs)\n",
        "    idf_values = {}\n",
        "    for doc in train_docs:\n",
        "        cleaned_doc = clean_text(doc)\n",
        "        words = set(cleaned_doc.split())\n",
        "        for word in words:\n",
        "            idf_values[word] = idf_values.get(word, 0) + 1\n",
        "    idf = {word: log10(N / df) for word, df in idf_values.items()}\n",
        "    return idf\n",
        "\n",
        "def compute_tfidf_weights(train_docs):\n",
        "    \"\"\"\n",
        "    Compute TF-IDF weights for a list of documents.\n",
        "\n",
        "    Parameters:\n",
        "    train_docs (list of str): The list of documents for which TF-IDF weights are to be computed.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: DataFrame containing TF values for words in each document.\n",
        "    pandas.DataFrame: DataFrame containing IDF values for words in the document corpus.\n",
        "    \"\"\"\n",
        "    # Compute TF values for each document\n",
        "    tf_values = compute_tf(train_docs)\n",
        "    # Compute IDF values for words in the document corpus\n",
        "    idf_values = compute_idf(train_docs)\n",
        "    # Convert TF values to DataFrame and fill NaN values with 0\n",
        "    docs_tf = pd.DataFrame(tf_values).fillna(0)\n",
        "    # Convert IDF values to DataFrame\n",
        "    docs_idf = pd.DataFrame(idf_values.values(), index=idf_values.keys(), columns=['idf'])\n",
        "    return docs_tf, docs_idf\n",
        "\n",
        "def word_tfidf_vector(word, tf_df, idf_df):\n",
        "    \"\"\"\n",
        "    Compute the TF-IDF vector for a specific word.\n",
        "\n",
        "    Parameters:\n",
        "    word (str): The word for which TF-IDF vector is to be computed.\n",
        "    tf_df (pandas.DataFrame): DataFrame containing TF values for words in each document.\n",
        "    idf_df (pandas.DataFrame): DataFrame containing IDF values for words in the document corpus.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Array containing TF-IDF vector for the given word.\n",
        "    \"\"\"\n",
        "    # Retrieve TF values for the given word\n",
        "    tf_values = tf_df[word]\n",
        "    # Retrieve IDF value for the given word\n",
        "    idf_value = idf_df.loc[word, 'idf']\n",
        "    # Compute TF-IDF vector for the word\n",
        "    tf_idf_value = np.array(tf_values * idf_value)\n",
        "    return tf_idf_value\n",
        "\n",
        "# Test cases\n",
        "train_docs = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\",\n",
        "]\n",
        "\n",
        "# Compute TF-IDF weights for the train documents\n",
        "docs_tf, docs_idf = compute_tfidf_weights(train_docs)\n",
        "print(\"TF DataFrame:\")\n",
        "print(docs_tf)\n",
        "print(\"\\nIDF DataFrame:\")\n",
        "print(docs_idf)\n",
        "\n",
        "# Test TF-IDF vector computation for a specific word\n",
        "word = 'document'\n",
        "tf_idf_vector = word_tfidf_vector(word, docs_tf, docs_idf)\n",
        "print(f\"\\nTF-IDF vector for '{word}':\")\n",
        "print(tf_idf_vector)\n"
      ]
    }
  ]
}